{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "import cerberus\n",
    "import schema\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 22352,\n",
      " 'meta': 1,\n",
      " 'nd': 1405875,\n",
      " 'node': 1278477,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 873,\n",
      " 'tag': 210917,\n",
      " 'way': 113652}\n"
     ]
    }
   ],
   "source": [
    "#Find top level tags in the data set and count them \n",
    "\n",
    "tags = {}\n",
    "\n",
    "def count_tags(filename):\n",
    "    for event, elem in ET.iterparse(filename ,events=(\"start\",)):\n",
    "        if elem.tag in tags.keys(): #Check if the tag is already in tags\n",
    "            tags[elem.tag] += 1     #Add 1 to the count if it is. \n",
    "        else:\n",
    "            tags[elem.tag] = 1      #If it isnt, set the count to 1\n",
    "    return tags\n",
    "\n",
    "with open('memphismap.xml', 'r') as mapfile:\n",
    "    pprint.pprint(count_tags(mapfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 157119, 'lower_colon': 51384, 'other': 2414, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "#Checking the k values for each tag for problem characters\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def check_k(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.match(element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys[\"lower_colon\"] +=1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys [\"other\"] += 1\n",
    "    pass\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = check_k(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "with open('memphismap.xml', 'r') as mapfile:\n",
    "    keys = process_map(mapfile)\n",
    "    pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n"
     ]
    }
   ],
   "source": [
    "#Finding unique user count\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if \"uid\" in element.attrib:\n",
    "            users.add(element.attrib[\"uid\"])\n",
    "        pass\n",
    "    return len(users)\n",
    "\n",
    "with open('memphismap.xml', 'r') as mapfile:\n",
    "    users = process_map(mapfile)\n",
    "    print users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'236': {'Lynnfield Road Suite 236'},\n",
       "             'Ave': {'Central Ave',\n",
       "              'Chelsea Ave',\n",
       "              'Lamar Ave',\n",
       "              'Shadyac Ave',\n",
       "              'W G E Patterson Ave'},\n",
       "             'Blvd': {'B.B. King Blvd', 'Ridge Lake Blvd'},\n",
       "             'Cir': {'E Brookhaven Cir'},\n",
       "             'Extended': {'Perkins Extended'},\n",
       "             'Front': {'Front'},\n",
       "             'Jackson': {'Jackson'},\n",
       "             'Main': {'Main'},\n",
       "             'Mississippi': {'Mississippi'},\n",
       "             'Pike': {'Covington Pike'},\n",
       "             'Poplar': {'Poplar'},\n",
       "             'Rd': {'Avon Rd'},\n",
       "             'Rd.': {'Clarke Rd.'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Auditing street Names\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",\"Freeway\",\"Circle\",\"Strand\",\"Sterling\",\"Way\",\"Highway\",\n",
    "            \"Terrace\",\"South\",\"East\",\"West\",\"North\", \"Cove\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s:s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit():\n",
    "    with open ('memphismap.xml', 'r') as mapfile:\n",
    "        street_types = defaultdict(set) #Tracks incorrect street types\n",
    "        for event, elem in ET.iterparse(mapfile, events=(\"start\", )):\n",
    "            if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "                for tag in elem.iter(\"tag\"):\n",
    "                    if is_street_name(tag):\n",
    "                        audit_street_type(street_types, tag.attrib['v'])\n",
    "        return street_types\n",
    "        \n",
    "audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covington Pike -> Covington Pike\n",
      "Mississippi -> Mississippi\n",
      "Perkins Extended -> Perkins Extended\n",
      "Jackson -> Jackson\n",
      "Front -> Front\n",
      "Avon Rd -> Avon Road \n",
      "E Brookhaven Cir -> E Brookhaven Circle \n",
      "Poplar -> Poplar\n",
      "Ridge Lake Blvd -> Ridge Lake Boulevard\n",
      "B.B. King Blvd -> B.B. King Boulevard\n",
      "Lamar Ave -> Lamar Avenue \n",
      "Shadyac Ave -> Shadyac Avenue \n",
      "W G E Patterson Ave -> W G East Patterson Ave\n",
      "Chelsea Ave -> Chelsea Avenue \n",
      "Central Ave -> Central Avenue \n",
      "Lynnfield Road Suite 236 -> Lynnfield Road Suite 236\n",
      "Main -> Main\n",
      "Clarke Rd. -> Clarke Road .\n"
     ]
    }
   ],
   "source": [
    "#Correcting Street Types\n",
    "\n",
    "mapping = {\n",
    "            \" St \": \" Street \",\n",
    "            \" St.\": \" Street \",\n",
    "            \" Rd.\": \" Road \",\n",
    "            \" Rd \": \" Road \",\n",
    "            \" Rd\": \" Road \",\n",
    "            \" Ave \": \" Avenue \", \n",
    "            \" Ave.\": \" Avenue \",\n",
    "            \" Av \": \" Avenue \",\n",
    "            \" Ave\" : \" Avenue \",\n",
    "            \" Dr \": \" Drive \",\n",
    "            \" Dr.\": \" Drive\",\n",
    "            \" Blvd \": \" Boulevard \",\n",
    "            \" Blvd\": \" Boulevard\",\n",
    "            \" Blvd.\": \" Boulevard\",\n",
    "            \" Ct \": \" Centre \",\n",
    "            \" Ctr\": \" Centre\",\n",
    "            \" Pl \": \" Place \",\n",
    "            \" Ln \": \" Lane \",\n",
    "            \" Cir \": \" Circle \",\n",
    "            \" Cir\" : \" Circle \",\n",
    "            \" Wy\": \" Way \",\n",
    "            \" S \": \" South \",\n",
    "            \" E \": \" East \",\n",
    "            \" W \": \" West \",\n",
    "            \" N \": \"North\"\n",
    "}\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for key, value in mapping.iteritems():\n",
    "        if key in name:\n",
    "            return name.replace(key, value)\n",
    "    return name\n",
    "\n",
    "with open ('memphismap.xml', 'r') as mapfile:\n",
    "    s_types = audit()\n",
    "    \n",
    "    for s_type, ways in s_types.iteritems():\n",
    "        for name in ways:\n",
    "            correct_name = update_name(name, mapping)\n",
    "            print name, \"->\", correct_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'38103': {'38103'},\n",
       "             '38104': {'38104'},\n",
       "             '38105': {'38105'},\n",
       "             '38106': {'38106'},\n",
       "             '38107': {'38107'},\n",
       "             '38108': {'38108'},\n",
       "             '38109': {'38109'},\n",
       "             '38111': {'38111'},\n",
       "             '38112': {'38112'},\n",
       "             '38114': {'38114'},\n",
       "             '38115': {'38115'},\n",
       "             '38117': {'38117'},\n",
       "             '38118': {'38118'},\n",
       "             '38119': {'38119'},\n",
       "             '38120': {'38120'},\n",
       "             '38122': {'38122'},\n",
       "             '38126': {'38126'},\n",
       "             '38128': {'38128'},\n",
       "             '3813': {'3813'},\n",
       "             '38134': {'38134'},\n",
       "             '38152': {'38152'},\n",
       "             '38163': {'38163'},\n",
       "             '3951': {'3951'}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Auditing street Names\n",
    "\n",
    "zip_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "zip_types = defaultdict(set)\n",
    "expected = []\n",
    "\n",
    "def audit_zip_code(zip_types, zip_name):\n",
    "    m = zip_type_re.search(zip_name)\n",
    "    if m:\n",
    "        zip_type = m.group()\n",
    "        if zip_type not in expected:\n",
    "            zip_types[zip_type].add(zip_name)\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s:s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v)\n",
    "\n",
    "def is_zip_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip():\n",
    "    with open ('memphismap.xml', 'r') as mapfile:\n",
    "        for event, elem in ET.iterparse(mapfile, events=(\"start\", )):\n",
    "            if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "                for tag in elem.iter(\"tag\"):\n",
    "                    if is_zip_code(tag):\n",
    "                        audit_zip_code(zip_types, tag.attrib['v'])\n",
    "        return zip_types\n",
    "        \n",
    "audit_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_zipcode(zipcode): \n",
    "    if len(str(zipcode))<5:\n",
    "        zipcode = 00000\n",
    "    return zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSM_PATH = open(\"memphismap.xml\", \"r\")\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in NODE_FIELDS:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        for child in element:\n",
    "            node_tag = {}\n",
    "            if LOWER_COLON.match(child.attrib['k']):\n",
    "                node_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                node_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                if child.attrib['k'] == \"addr:street\":\n",
    "                    node_tag['value'] = update_name(child.attrib['v'], mapping)\n",
    "                elif child.attrib['k'] == \"addr:postcode\":\n",
    "                    node_tag['value'] = update_zipcode(child.attrib['v'])\n",
    "                tags.append(node_tag)\n",
    "            elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                continue\n",
    "            else:\n",
    "                node_tag['type'] = 'regular'\n",
    "                node_tag['key'] = child.attrib['k']\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "        \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in WAY_FIELDS:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        position = 0\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "            \n",
    "            if child.tag == 'tag':\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    way_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                    way_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    if child.attrib['k'] == \"addr:street\":\n",
    "                        way_tag['value'] = update_name(child.attrib['v'], mapping)\n",
    "                    elif child.attrib['k'] == \"addr:postcode\":\n",
    "                        way_tag['value'] = update_zipcode(child.attrib['v'])\n",
    "                    tags.append(way_tag)\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "                    \n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"memphis.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the table exists and dropping it if it does, then create the table. \n",
    "cur.execute(\"DROP TABLE IF EXISTS nodes;\")\n",
    "db.commit()\n",
    "cur.execute(\"CREATE TABLE nodes (id INTEGER PRIMARY KEY NOT NULL,lat REAL,lon REAL,user TEXT,uid INTEGER,version INTEGER,changeset INTEGER,timestamp TEXT);\")\n",
    "db.commit()\n",
    "\n",
    "#Read the csv file\n",
    "with open('nodes.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['lat'].decode(\"utf-8\"),i['lon'].decode(\"utf-8\"),i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),i['changeset'].decode(\"utf-8\"),i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "#Insert the data into the table\n",
    "cur.executemany(\"INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?,?,?);\", to_db)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes_tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS nodes_tags;\")\n",
    "db.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE nodes_tags (id INTEGER, key TEXT, value TEXT, type TEXT, FOREIGN KEY (id) REFERENCES nodes(id))\")\n",
    "db.commit()\n",
    "\n",
    "with open('nodes_tags.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS ways;\")\n",
    "db.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways(id INTEGER PRIMARY KEY NOT NULL,user TEXT,uid INTEGER,version TEXT,changeset INTEGER,timestamp TEXT);\")\n",
    "db.commit()\n",
    "\n",
    "with open('ways.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),i['changeset'].decode(\"utf-8\"),i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways (id, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?);\", to_db)\n",
    "db.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways_nodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS ways_nodes;\")\n",
    "db.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_nodes (id INTEGER NOT NULL,node_id INTEGER NOT NULL,position INTEGER NOT NULL,FOREIGN KEY (id) REFERENCES ways(id),FOREIGN KEY (node_id) REFERENCES nodes(id));\")\n",
    "db.commit()\n",
    "\n",
    "with open('ways_nodes.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['node_id'].decode(\"utf-8\"),i['position'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes (id, node_id, position) VALUES (?,?,?);\", to_db)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways_tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS ways_tags;\");\n",
    "db.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_tags (id INTEGER NOT NULL,key TEXT NOT NULL,value TEXT NOT NULL,type TEXT,FOREIGN KEY (id) REFERENCES ways(id));\")\n",
    "db.commit()\n",
    "\n",
    "with open('ways_tags.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memphismap.xml ..... 247 MB\n",
      "memphis.db ..... 122 MB\n",
      "nodes.csv ..... 101 MB\n",
      "nodes_tags.csv ..... 0 MB\n",
      "ways.csv ..... 6 MB\n",
      "ways_tags.csv ..... 6 MB\n",
      "ways_nodes.csv ..... 33 MB\n"
     ]
    }
   ],
   "source": [
    "print 'memphismap.xml', '.....', (os.path.getsize(\"memphismap.xml\")/(1024*1024)), 'MB'\n",
    "print 'memphis.db', '.....', (os.path.getsize(\"memphis.db\")/(1024*1024)), 'MB'\n",
    "print 'nodes.csv', '.....', (os.path.getsize(\"nodes.csv\")/(1024*1024)), 'MB'\n",
    "print 'nodes_tags.csv', '.....', (os.path.getsize(\"nodes_tags.csv\")/(1024*1024)), 'MB'\n",
    "print 'ways.csv', '.....', (os.path.getsize(\"ways.csv\")/(1024*1024)), 'MB'\n",
    "print 'ways_tags.csv', '.....', (os.path.getsize(\"ways_tags.csv\")/(1024*1024)), 'MB'\n",
    "print 'ways_nodes.csv', '.....', (os.path.getsize(\"ways_nodes.csv\")/(1024*1024)), 'MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of nodes and ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1278477,)]\n"
     ]
    }
   ],
   "source": [
    "#Number of nodes\n",
    "query = cur.execute('SELECT COUNT(*) FROM nodes')\n",
    "print query.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(113652,)]\n"
     ]
    }
   ],
   "source": [
    "#Number of ways\n",
    "query = cur.execute('SELECT COUNT(*) FROM ways')\n",
    "print query.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(676,)\n"
     ]
    }
   ],
   "source": [
    "query = cur.execute('SELECT COUNT(distinct(uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways)')\n",
    "pprint.pprint(query.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User with the most submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'OSM901', 1239829)]\n"
     ]
    }
   ],
   "source": [
    "#Number of ways\n",
    "query = cur.execute('SELECT e.user, COUNT(*) AS num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS e GROUP BY user ORDER BY num DESC LIMIT 1;')\n",
    "pprint.pprint(query.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number and type of religious locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'christian', 720),\n",
      " (u'jewish', 7),\n",
      " (u'muslim', 5),\n",
      " (u'multifaith', 1),\n",
      " (u'hindu', 1)]\n"
     ]
    }
   ],
   "source": [
    "query= cur.execute(\"SELECT value, COUNT(*) AS num FROM (SELECT key,value FROM nodes_tags UNION ALL SELECT key,value FROM ways_tags) AS e WHERE key='religion' GROUP BY value ORDER BY num DESC;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of resturaunts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'burger', 18),\n",
      " (u'american', 12),\n",
      " (u'sandwich', 8),\n",
      " (u'mexican', 8),\n",
      " (u'chicken', 8),\n",
      " (u'pizza', 7),\n",
      " (u'coffee_shop', 7),\n",
      " (u'japanese', 4),\n",
      " (u'italian', 4),\n",
      " (u'barbecue', 4),\n",
      " (u'tex-mex', 3),\n",
      " (u'seafood', 3),\n",
      " (u'ice_cream', 3),\n",
      " (u'regional', 2),\n",
      " (u'chinese', 2),\n",
      " (u'asian', 2),\n",
      " (u'wings', 1),\n",
      " (u'vietnamese', 1),\n",
      " (u'thai', 1),\n",
      " (u'steak_house', 1),\n",
      " (u'southern;breakfast', 1),\n",
      " (u'pretzel', 1),\n",
      " (u'pizza;barbecue;steak;southern;breakfast;lunch', 1),\n",
      " (u'mediterranean;korean;sandwich', 1),\n",
      " (u'gastropub', 1),\n",
      " (u'donut', 1),\n",
      " (u'diner', 1),\n",
      " (u'cookies', 1),\n",
      " (u'coffee_shop;southern', 1),\n",
      " (u'coffee;tea', 1),\n",
      " (u'chinese;sushi', 1),\n",
      " (u'chinese;buffet', 1),\n",
      " (u'cake;bagel;coffee_shop', 1),\n",
      " (u'breakfast;pancake', 1),\n",
      " (u'breakfast;coffee_shop', 1),\n",
      " (u'breakfast', 1),\n",
      " (u'bar;hotdogs', 1),\n",
      " (u'arab', 1),\n",
      " (u'american;steak', 1),\n",
      " (u'african', 1),\n",
      " (u'Club_and_Southern_Food', 1),\n",
      " (u'Bar_and_Pub_food', 1),\n",
      " (u'BBQ', 1)]\n"
     ]
    }
   ],
   "source": [
    "query=cur.execute(\"SELECT value, COUNT(*) AS num FROM (SELECT key,value FROM nodes_tags UNION ALL SELECT key,value FROM ways_tags) AS e WHERE e.key LIKE '%cuisine%' GROUP BY value ORDER BY num desc;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
